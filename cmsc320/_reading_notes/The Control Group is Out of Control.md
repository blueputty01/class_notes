[The Control Group is Out of Control](https://slatestarcodex.com/2014/04/28/the-control-group-is-out-of-control/)
# I. 

Parapsychology (study of psychic phenomena): the control group for science

“placebo effect” in science – ie with enough energy focused on a subject, you can always produce “experimental evidence” for it that meets the usual scientific standards. 

Parapsychologists are constantly protesting that they are playing by all the standard scientific rules, and yet their results are being ignored – that they are unfairly being held to higher standards than everyone else. I’m willing to believe that. It just means that the standard statistical methods of science are so weak and flawed as to permit a field of study to sustain itself in the complete absence of any subject matter.

Psychologists admit to a crisis of replication as some of their most interesting findings turn out to be spurious.

promising directions to determine what is actually right: 

1. Demand very **large sample size.**
2. Demand replication, preferably **exact replication,** most preferably multiple exact replications.
3. Trust systematic reviews and **meta-analyses** rather than individual studies. Meta-analyses must prove homogeneity of the studies they analyze.
4. Use **Bayesian rather than frequentist analysis,** or even combine both techniques.
5. **Stricter p-value criteria.** It is far too easy to massage p-values to get less than 0.05. Also, make meta-analyses look for “p-hacking” by examining the distribution of p-values in the included studies.
6. Require pre-registration of trials.
7. **Address publication bias** by searching for unpublished trials, displaying funnel plots, and using statistics like “fail-safe N” to investigate the possibility of suppressed research.
8. Do heterogeneity analyses or at least observe and **account for differences in the studies you analyze.**
9. Demand **randomized controlled trials.** None of this “correlated even after we adjust for confounders” BS.
10. **Stricter effect size criteria.** It’s easy to get small effect sizes in anything.

Effect size tells you how meaningful the relationship between variables or the difference between groups is. A large effect size means that a research finding has practical significance, while a small effect size indicates limited practical applications.

# II

# III 

The first nine items try to solve the same problem: accidentally mistaking noise in the data for a signal.

Poor experimental technique is important. Experiment must not be confounded

garbage in -> garbage out

# IV

two guys proving opposite things come together to try to prove the other wrong with the exact same experiment and end up with the results they had each expected

# V 

Other than a few very exceptional large medical trials, there is not a study in the world that would survive the level of criticism I am throwing at Bem right now.

# VI 

Pyramid of Scientific Evidence 

Lowest level is personal opinion, then systematic reviews and meta analysis



