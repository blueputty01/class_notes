SLO means **Service Level Objective**, or **1::a target value or range of values for a service level**

---

Putting it All Together
- Ingestion: Data is pulled into where the model needs it
- Processing: Process it
- Inference: The model does its actual inference
- Serving: The model needs to be able to send its inference to wherever it needs to go
- Monitoring: We need to be able to make sure the model is up and functioning
- Reporting: We need to be able to see how well the model does

---

You should create logs / alerts for:
- Data missing: If you ever are pulling an order of magnitude more data than usual, or less, this needs to be an alert
- Data in the wrong format: This will crash your model; you need to know where this step happened
- **Resource issues: Your model cannot get access to the compute it needs**
- Process timeout: Your model has a method that's in an infinite loop or can't finish

Every change will require a(n) **experiment** on a **1::portion of traffic**.
> experiments will often be A/B testing
> can happen on different planes (so often multiple independent experiments at the same time)



***
