Convolutional neural networks contain three main types of layers:
- **1::convolutional** layer
- **1::pooling** layer
- **1::fully connected (FC)** layer
> each layer identifies a greater portion of image (colors and edges -> shapes -> objects)

The convolutional layer requires:
- **input data**
- **1::filter**
- **1::feature map**

The feature detector is a **two-dimensional (2-D) array of weights**, which represents part of the image.
> typically 3x3 matrix
> a dot product is calculated between the input pixels and the filter
> activation for the $(j, k)$ neuron is $\sigma\left(b+\sum_{l=0}^{4}\sum_{m=0}^{4}w_{l,m}a_{j+l,k+m}\right)$

**Zero-padding** is usually used when the filters do not fit the input image.
> This sets all elements that fall outside of the input matrix to zero, producing a larger or equally sized output. There are three types of padding:
> - **Valid padding:** This is also known as no padding. In this case, the last convolution is dropped if dimensions do not align.
> - **Same padding:** This padding ensures that the output layer has the same size as the input layer.
> - **Full padding:** This type of padding increases the size of the output by adding zeros to the border of the input.
> CNN hyperparameters: number of filters, stride, zero padding

**Stride** defines the number of pixel the kernel moves for each iteration
> for example stride of 1 makes kernel slide by one row/column at a time and stride of 2 moves kernel by 2 rows/columns.
> CNN hyperparameters: number of filters, stride, zero padding

**Pooling layers**: kernel applies **aggregation function to the values within receptive field**.
+
Types: **max (more common)**, **3::average** pooling
> while a lot of information is lost in the pooling layer, the pooling layer helps reduce complexity, improve efficiency, and limit risk of over fitting
> here each pixel in the pooling layer is looking at a 2x2 section of previous layer
> also known as downsampling

While convolutional and pooling layers tend to use ReLu functions, FC layers usually leverage a softmax activation function to classify inputs appropriately, producing **a probability from 0 to 1**.

Training process for image classification networks: 
1. show the network $n$ pictures, where $n$ is your batch size.
2. Use the backpropogation algorithm, but randomly pick some number of weights not to update, based on your **dropout** rate. 
3. Repeat until network loss stops decreasing.
> higher dropout rate will prevent overfitting and increase the speed, but too high and model will underfit

**Transfer learning** is a machine learning technique where knowledge gained from a pre-trained model on one task is reused to improve performance on a related, but different, task.

For transfer learning for image classification, use the **second to last** layer of a pre-trained model, as it contains **the most general features of the image**.

***
